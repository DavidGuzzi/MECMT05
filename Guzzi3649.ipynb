{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UNIVERSIDAD TORCUATO DI TELLA**\n",
    "## **MAESTRÍA EN ECONOMETRÍA**\n",
    "\n",
    "---\n",
    "\n",
    "### **TRABAJO PRÁCTICO DE ECONOMETRÍA**\n",
    "\n",
    "- **Profesor:** González-Rozada, Martín  \n",
    "- **Ayudante:** Lening, Iara  \n",
    "- **Alumno:** Guzzi, David Alexander  (Legajo n°: 24H1970, DNI: 37.703.649)  \n",
    "\n",
    "**Ciclo Lectivo:** Tercer Trimestre, 2024  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. PROPIEDADES DE MUESTRA FINITA DE FGLS (MCGE).**\n",
    "\n",
    "Considere el siguiente modelo:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y_i = \\beta_0 + \\beta_1 x_i + u_i, \\quad i = 1, 2, \\dots, 5N\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $\\beta_0 = -3$\n",
    "- $\\beta_1 = 0.8$\n",
    "- $u_j \\sim N(0, \\omega \\cdot I_{N \\times N})$, con la matriz $\\Omega$ definida como:\n",
    "\n",
    "$$\n",
    "\\Omega = \\begin{bmatrix}\n",
    "4 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 9 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 16 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 25 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 36\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- $x_j \\sim U[1, 50]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "\n",
    "# Semilla para la generación de números aleatorios.\n",
    "np.random.seed(3649)\n",
    "\n",
    "# Configuración de pandas (4 decimales).\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgls_estimation(x: np.ndarray, y: np.ndarray) -> tuple[float, float, float]:\n",
    "\n",
    "    \"\"\"\n",
    "    Realiza una estimación de Feasible Generalized Least Squares (FGLS para un modelo lineal \n",
    "    con errores heterocedásticos.\n",
    "\n",
    "    Parámetros:\n",
    "    x : array-like\n",
    "        Variable regresora.\n",
    "    y : array-like\n",
    "        Variable de respuesta.\n",
    "\n",
    "    Retorna:\n",
    "    beta0_fgls : float\n",
    "        Intercepto estimado.\n",
    "    beta1_fgls : float\n",
    "        Coeficiente estimado para el regresor.\n",
    "    se_beta1_fgls : float\n",
    "        Error estándar del coeficiente estimado para el regresor.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Estimar modelo inicial y ~ x por OLS y obtener las estimaciones de los parámetros del modelo.\n",
    "    X = np.column_stack((np.ones_like(x), x)) \n",
    "    beta_ols = np.linalg.inv(X.T @ X) @ X.T @ y \n",
    "\n",
    "    # 2. Calcular los residuos del modelo, elevarlos al cuadrado y obtener el logaritmo de los mismos.\n",
    "    u_hat = y - X @ beta_ols\n",
    "    u_hat2 = u_hat ** 2  \n",
    "    log_u_hat2 = np.log(u_hat2)\n",
    "\n",
    "    # 3. Dada la forma funcional de la heterocedasticidad de White para este modelo, sigma2 ~ x + x2, \n",
    "    # se estima por OLS usando u_hat2 como proxy de sigma2.\n",
    "    X_aux = np.column_stack((x, x**2))\n",
    "    gamma_hat = np.linalg.inv(X_aux.T @ X_aux) @ X_aux.T @ log_u_hat2\n",
    "    \n",
    "    # 4. Usar las estimaciones de la regresión auxiliar y obtener las varianzas ajustadas (no consistentes).\n",
    "    log_sigma2_hat = X_aux @ gamma_hat\n",
    "    sigma2_hat = np.exp(log_sigma2_hat)\n",
    "\n",
    "    # 5. Transformar las variables de la forma funcional de la heterocedasticidad de White dividiéndolas por sigma2_hat y estimar por OLS.\n",
    "    X_aux2 = np.column_stack((x / sigma2_hat,  x**2 / sigma2_hat))\n",
    "    u_hat2_over_sigma2_hat = u_hat2 / sigma2_hat\n",
    "    gamma_hat2 = np.linalg.inv(X_aux2.T @ X_aux2) @ X_aux2.T @ u_hat2_over_sigma2_hat\n",
    "\n",
    "    # 6. Usar las estimaciones de la segunda regresión auxiliar y obtener las varianzas ajustadas (consistentes).\n",
    "    sigma2_tilde = np.maximum(X_aux @ gamma_hat2, 1e-6) #Se asegura positividad de las varianzas. \n",
    "    omega_tilde_inv = np.linalg.inv(np.diag(sigma2_tilde)) #Se construye matriz omega inversa.  \n",
    "    \n",
    "    # 7. Aplicar GLS en la regresión de y ~ x, utilizando como ponderador la matriz omega estimada.\n",
    "    # Obs.: También se podría usar uno sobre la raíz cuadrada de sigma2 tilde como ponderador en la regresión de y ~ x.\n",
    "    \n",
    "    # Se obtienen las estimaciones de los parámetros.\n",
    "    beta_fgls = np.linalg.inv(X.T @ omega_tilde_inv @ X) @ X.T @ omega_tilde_inv @ y\n",
    "    \n",
    "    # Se obtienen las estimaciones de los errores estándar de los parámetros.\n",
    "    residuals_fgls = y - X @ beta_fgls\n",
    "    s2_fgls = (residuals_fgls.T @ omega_tilde_inv @ residuals_fgls) / ( X.shape[0] - X.shape[1])\n",
    "    var_beta_fgls = s2_fgls * np.linalg.inv(X.T @ omega_tilde_inv @ X)\n",
    "    se_beta1_fgls = np.sqrt(np.diag(var_beta_fgls))[1]   \n",
    "    \n",
    "    return beta_fgls[0], beta_fgls[1], se_beta1_fgls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_fgls(n_samples: int, n_observations_list: list[int], beta_0_true: float, beta_1_true: float, beta1_H0: float) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Simula la estimación de FGLS para distintos tamaños de muestra y evalúa la validez de un test de hipótesis.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        Número de simulaciones a realizar para cada tamaño de muestra.\n",
    "    n_observations_list : list of int\n",
    "        Lista con los distintos tamaños de muestra a evaluar.\n",
    "    beta_0_true : float\n",
    "        Valor verdadero del intercepto en la simulación.\n",
    "    beta_1_true : float\n",
    "        Valor verdadero del coeficiente del regresor en la simulación.\n",
    "    beta1_H0 : float\n",
    "        Valor hipotético de beta_1 bajo H0 para el test de hipótesis.\n",
    "\n",
    "    Returns:\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame con estadísticas de los coeficientes estimados y tasas de rechazo del test de hipótesis.\n",
    "        Columnas:\n",
    "        - 'n_observations': Tamaño de la muestra.\n",
    "        - 'mean_beta0': Media de las estimaciones de beta_0.\n",
    "        - 'median_beta0': Mediana de las estimaciones de beta_0.\n",
    "        - 'std_beta0': Desviación estándar de las estimaciones de beta_0.\n",
    "        - 'mean_beta1': Media de las estimaciones de beta_1.\n",
    "        - 'median_beta1': Mediana de las estimaciones de beta_1.\n",
    "        - 'std_beta1': Desviación estándar de las estimaciones de beta_1.\n",
    "        - 'test_size_1pct': Proporción de rechazos de H0 al 1% de significancia.\n",
    "        - 'test_size_5pct': Proporción de rechazos de H0 al 5% de significancia.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    for n_obs in n_observations_list:\n",
    "        sample_results = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            # Generación de datos.\n",
    "            x = np.random.uniform(1, 50, n_obs) # x ~ U[1, 50]\n",
    "            u = np.random.normal(scale=x) # u ~ N(0, omega), con varianza heterocedástica dependiendo de x.\n",
    "            y = beta_0_true + beta_1_true * x + u\n",
    "            \n",
    "            # Estimación FGLS.\n",
    "            beta_0_hat, beta_1_hat, se_beta1_hat = fgls_estimation(x, y)\n",
    "            \n",
    "            # Test de hipótesis para beta_1 = beta1_H0.\n",
    "            t_stat = (beta_1_hat - beta1_H0) / se_beta1_hat\n",
    "            p_value = 2 * (1 - t.cdf(abs(t_stat), df=n_obs - 2))\n",
    "            reject_1pct = p_value < 0.01 # Rechazar H0 al 1% de significancia.\n",
    "            reject_5pct = p_value < 0.05 # Rechazar H0 al 5% de significancia.\n",
    "            \n",
    "            sample_results.append([beta_0_hat, beta_1_hat, reject_1pct, reject_5pct])\n",
    "        \n",
    "        # Convertir a DataFrame.\n",
    "        df_results = pd.DataFrame(sample_results, columns=['beta_0_hat', 'beta_1_hat', 'reject_1pct', 'reject_5pct'])\n",
    "        \n",
    "        # Calcular estadísticas.\n",
    "        mean_beta0 = df_results['beta_0_hat'].mean()\n",
    "        mean_beta1 = df_results['beta_1_hat'].mean()\n",
    "        median_beta0 = df_results['beta_0_hat'].median()\n",
    "        median_beta1 = df_results['beta_1_hat'].median()\n",
    "        std_beta0 = df_results['beta_0_hat'].std()\n",
    "        std_beta1 = df_results['beta_1_hat'].std()\n",
    "        test_1pct = df_results['reject_1pct'].mean() #Equivale a la proporción de rechazos de las 5000 simulaciones al 1% de significancia.\n",
    "        test_5pct = df_results['reject_5pct'].mean() #Equivale a la proporción de rechazos de las 5000 simulaciones al 5% de significancia.\n",
    "        \n",
    "        results.append([n_obs, mean_beta0, median_beta0, std_beta0, mean_beta1, median_beta1, std_beta1, test_1pct, test_5pct])\n",
    "    \n",
    "    results_df = pd.DataFrame(results, columns=['n_observations', 'mean_beta0', 'median_beta0', 'std_beta0', 'mean_beta1', 'median_beta1', 'std_beta1', 'test_1pct', 'test_5pct'])\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_gls(n_samples: int, n_observations: int, beta_0_true: float, beta_1_true: float, beta1_H0: float, omega: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula la estimación de GLS para un determinado tamaño de muestra y evalúa la validez de un test de hipótesis.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        Número de simulaciones a realizar para cada tamaño de muestra.\n",
    "    n_observations : int\n",
    "        Tamaño de la muestra.\n",
    "    beta_0_true : float\n",
    "        Valor verdadero del intercepto en la simulación.\n",
    "    beta_1_true : float\n",
    "        Valor verdadero del coeficiente del regresor en la simulación.\n",
    "    beta1_H0 : float\n",
    "        Valor hipotético de beta_1 bajo H0 para el test de hipótesis.\n",
    "    omega : np.ndarray\n",
    "        Matriz de varianzas y covarianzas de los errores.\n",
    "\n",
    "    Returns:\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame con estadísticas de los coeficientes estimados y tasas de rechazo del test de hipótesis.\n",
    "        Columnas:\n",
    "        - 'n_observations': Tamaño de la muestra.\n",
    "        - 'mean_beta0': Media de las estimaciones de beta_0.\n",
    "        - 'median_beta0': Mediana de las estimaciones de beta_0.\n",
    "        - 'std_beta0': Desviación estándar de las estimaciones de beta_0.\n",
    "        - 'mean_beta1': Media de las estimaciones de beta_1.\n",
    "        - 'median_beta1': Mediana de las estimaciones de beta_1.\n",
    "        - 'std_beta1': Desviación estándar de las estimaciones de beta_1.\n",
    "        - 'test_size_1pct': Proporción de rechazos de H0 al 1% de significancia.\n",
    "        - 'test_size_5pct': Proporción de rechazos de H0 al 5% de significancia.\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_results = []\n",
    "\n",
    "    # Descomposición de Cholesky de omega\n",
    "    omega = np.diag(omega)\n",
    "    P = np.linalg.cholesky(omega)\n",
    "    P_inv = np.linalg.inv(P)\n",
    "\n",
    "    # Simulación de M muestras\n",
    "    for _ in range(n_samples):\n",
    "        # 1. Generar muestra.\n",
    "        x = np.random.uniform(1, 50, n_observations)  # x ~ U[1, 50]\n",
    "        u = np.random.multivariate_normal(mean=np.zeros(n_observations), cov=omega)  # u ~ N(0, omega)\n",
    "        y = beta_0_true + beta_1_true * x + u\n",
    "\n",
    "        # 2. Transformar para GLS.\n",
    "        y_tilde = P_inv @ y\n",
    "        X = np.column_stack((np.ones(n_observations), x))  # Matriz de diseño original\n",
    "        X_tilde = P_inv @ X\n",
    "\n",
    "        # 3. Ajustar modelo transformado con OLS para obtener estimadores y desvío estándar de los mismos.\n",
    "        beta_hat = np.linalg.inv(X_tilde.T @ X_tilde) @ (X_tilde.T @ y_tilde)\n",
    "        residuals = y_tilde - X_tilde @ beta_hat\n",
    "        s2 = (residuals @ residuals) / (n_observations - X_tilde.shape[1])\n",
    "        var_beta_hat = s2 * np.linalg.inv(X_tilde.T @ X_tilde)\n",
    "        se_beta1_hat = np.sqrt(np.diag(var_beta_hat))[1]\n",
    "\n",
    "        # 4. Test de hipótesis para beta_1 = beta1_H0 (tamaño del test).\n",
    "        t_stat = (beta_hat[1] - beta1_H0) / se_beta1_hat\n",
    "        p_value = 2 * (1 - t.cdf(abs(t_stat), df=n_observations - 2))\n",
    "        reject_1pct = p_value < 0.01  # Rechazar H0 al 1% de significancia.\n",
    "        reject_5pct = p_value < 0.05  # Rechazar H0 al 5% de significancia.\n",
    "\n",
    "        sample_results.append([beta_hat[0], beta_hat[1], reject_1pct, reject_5pct])\n",
    "\n",
    "    # Convertir a DataFrame.\n",
    "    df_results = pd.DataFrame(sample_results, columns=['beta_0_hat', 'beta_1_hat', 'reject_1pct', 'reject_5pct'])\n",
    "\n",
    "    # Calcular estadísticas.\n",
    "    results = {\n",
    "        'n_observations': n_observations,\n",
    "        'mean_beta0': df_results['beta_0_hat'].mean(),\n",
    "        'median_beta0': df_results['beta_0_hat'].median(),\n",
    "        'std_beta0': df_results['beta_0_hat'].std(),\n",
    "        'mean_beta1': df_results['beta_1_hat'].mean(),\n",
    "        'median_beta1': df_results['beta_1_hat'].median(),\n",
    "        'std_beta1': df_results['beta_1_hat'].std(),\n",
    "        'test_size_1pct': df_results['reject_1pct'].mean(),\n",
    "        'test_size_5pct': df_results['reject_5pct'].mean()\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios.**\n",
    "1. Genere **5000 muestras de 5N = 5 observaciones** de corte transversal a partir del modelo (1):\n",
    "     \n",
    "   **a)** Para cada muestra estime por **FGLS** los parámetros del modelo y realice un test de hipótesis para contrastar que $H_0$ : $\\beta_1$  = 0.8. Reporte **tamaño del test** al 1% y 5% y el **poder del test** cuando $\\beta_1$ = 0 y $\\beta_1$ = 0.4. Adicionalmente, reporte la media, mediana y desvio estándar de las estimaciones de $\\beta_0$ y $\\beta_1$.\n",
    "\n",
    "   **b)** Utilice la **descomposición de Cholesky** para encontrar una matriz $\\Omega = P P'$ y aplique la transformación correspondiente a **GLS** al modelo (1) y estime el modelo por **OLS**, comente si cambia algún resultado.\n",
    "\n",
    "2. Repita el punto anterior (sólo el inciso a)) con **5N = 10**.\n",
    "\n",
    "3. Repita el punto anterior (sólo el inciso a)) con **5N = 30**.\n",
    "\n",
    "4. Repita el punto anterior (sólo el inciso a)) con **5N = 100**.\n",
    "\n",
    "5. Repita el punto anterior (sólo el inciso a)) con **5N = 200**.\n",
    "\n",
    "6. Repita el punto anterior (sólo el inciso a)) con **5N = 500**.\n",
    "\n",
    "7. Describa detalladamente las **propiedades de muestra finita de FGLS** de acuerdo a lo que observó de los cuatro puntos anteriores. En especial, explique **cómo cambia el tamaño y el poder de los tests** a medida que aumenta el tamaño de muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios 1a, 2, 3, 4, 5, 6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se generan 5.000 muestras para 5N = 5, 10, 30, 100, 200, 500. Se fija beta_0 = -3 y beta_1 = 0.8, y se obtienen estadísticas descriptivas. Se evalúa H0: beta_1 = 0.8 (tamaño del test). \n",
    "simulate_fgls(n_samples=5000, n_observations_list=[5, 10, 30, 100, 200, 500], beta_0_true=-3, beta_1_true=0.8, beta1_H0=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_observations</th>\n",
       "      <th>mean_beta0</th>\n",
       "      <th>median_beta0</th>\n",
       "      <th>std_beta0</th>\n",
       "      <th>mean_beta1</th>\n",
       "      <th>median_beta1</th>\n",
       "      <th>std_beta1</th>\n",
       "      <th>test_1pct</th>\n",
       "      <th>test_5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>-3.0200</td>\n",
       "      <td>-3.0115</td>\n",
       "      <td>1.8553</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>1.6837</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>-3.0054</td>\n",
       "      <td>-2.9938</td>\n",
       "      <td>1.6094</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.4567</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200</td>\n",
       "      <td>-2.9859</td>\n",
       "      <td>-2.9945</td>\n",
       "      <td>1.1024</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>-2.9848</td>\n",
       "      <td>-3.0003</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>-2.9913</td>\n",
       "      <td>-2.9926</td>\n",
       "      <td>0.2693</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.7992</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_observations  mean_beta0  median_beta0  std_beta0  mean_beta1  \\\n",
       "0             700     -3.0200       -3.0115     1.8553      0.8116   \n",
       "1            1000     -3.0054       -2.9938     1.6094      0.8088   \n",
       "2            1200     -2.9859       -2.9945     1.1024      0.7919   \n",
       "3            1500     -2.9848       -3.0003     0.8170      0.7858   \n",
       "4            2000     -2.9913       -2.9926     0.2693      0.7976   \n",
       "\n",
       "   median_beta1  std_beta1  test_1pct  test_5pct  \n",
       "0        0.7993     1.6837     0.0292     0.0690  \n",
       "1        0.8000     1.4567     0.0236     0.0606  \n",
       "2        0.8000     0.9931     0.0166     0.0584  \n",
       "3        0.8009     0.7410     0.0146     0.0528  \n",
       "4        0.7992     0.1837     0.0112     0.0472  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionalmente, se generan 5.000 muestras para 5N = 700, 1000, 1200, 1500, 2000 para observar en qué tamaño de muestra se obtiene un tamaño de test más cercano al nivel de significancia.\n",
    "simulate_fgls(n_samples=5000, n_observations_list=[700, 1000, 1200, 1500, 2000], beta_0_true=-3, beta_1_true=0.8, beta1_H0=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_observations</th>\n",
       "      <th>mean_beta0</th>\n",
       "      <th>median_beta0</th>\n",
       "      <th>std_beta0</th>\n",
       "      <th>mean_beta1</th>\n",
       "      <th>median_beta1</th>\n",
       "      <th>std_beta1</th>\n",
       "      <th>test_1pct</th>\n",
       "      <th>test_5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9.2582</td>\n",
       "      <td>-2.6233</td>\n",
       "      <td>893.4464</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>22.2380</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>18.4817</td>\n",
       "      <td>-2.9402</td>\n",
       "      <td>994.5864</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0.7957</td>\n",
       "      <td>23.2917</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.2470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>-14.9002</td>\n",
       "      <td>-2.9858</td>\n",
       "      <td>630.7914</td>\n",
       "      <td>1.0043</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>13.5219</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.3766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>-4.3804</td>\n",
       "      <td>-3.0011</td>\n",
       "      <td>88.5079</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>3.1786</td>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>-2.9602</td>\n",
       "      <td>-2.9970</td>\n",
       "      <td>8.5433</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>2.8978</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>-2.9962</td>\n",
       "      <td>-2.9792</td>\n",
       "      <td>2.0976</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>1.7883</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.9974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_observations  mean_beta0  median_beta0  std_beta0  mean_beta1  \\\n",
       "0               5      9.2582       -2.6233   893.4464      0.4592   \n",
       "1              10     18.4817       -2.9402   994.5864      0.3145   \n",
       "2              30    -14.9002       -2.9858   630.7914      1.0043   \n",
       "3             100     -4.3804       -3.0011    88.5079      0.8393   \n",
       "4             200     -2.9602       -2.9970     8.5433      0.8055   \n",
       "5             500     -2.9962       -2.9792     2.0976      0.8099   \n",
       "\n",
       "   median_beta1  std_beta1  test_1pct  test_5pct  \n",
       "0        0.7869    22.2380     0.1182     0.2262  \n",
       "1        0.7957    23.2917     0.1344     0.2470  \n",
       "2        0.8017    13.5219     0.2010     0.3766  \n",
       "3        0.8005     3.1786     0.6884     0.8616  \n",
       "4        0.8000     2.8978     0.9600     0.9864  \n",
       "5        0.7984     1.7883     0.9964     0.9974  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se generan 5.000 muestras para 5N = 5, 10, 30, 100, 200, 500. Se fija beta_0 = -3 y beta_1 = 0.8, y se obtienen estadísticas descriptivas. Se evalúa H0: beta_1 = 0.4 (poder del test). \n",
    "simulate_fgls(n_samples=5000, n_observations_list=[5, 10, 30, 100, 200, 500], beta_0_true=-3, beta_1_true=0.8, beta1_H0=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_observations</th>\n",
       "      <th>mean_beta0</th>\n",
       "      <th>median_beta0</th>\n",
       "      <th>std_beta0</th>\n",
       "      <th>mean_beta1</th>\n",
       "      <th>median_beta1</th>\n",
       "      <th>std_beta1</th>\n",
       "      <th>test_1pct</th>\n",
       "      <th>test_5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.7059</td>\n",
       "      <td>-3.0860</td>\n",
       "      <td>1245.7746</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.7938</td>\n",
       "      <td>33.4404</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>75.3163</td>\n",
       "      <td>-2.9185</td>\n",
       "      <td>4386.8609</td>\n",
       "      <td>-0.9077</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>98.9208</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>-11.9590</td>\n",
       "      <td>-3.0124</td>\n",
       "      <td>559.0582</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>11.6853</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>-3.3895</td>\n",
       "      <td>-2.9896</td>\n",
       "      <td>35.6139</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>3.2351</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>-3.0301</td>\n",
       "      <td>-2.9915</td>\n",
       "      <td>3.4799</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>2.1781</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>-3.0554</td>\n",
       "      <td>-3.0077</td>\n",
       "      <td>2.0244</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>1.7780</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_observations  mean_beta0  median_beta0  std_beta0  mean_beta1  \\\n",
       "0               5      1.7059       -3.0860  1245.7746      0.5090   \n",
       "1              10     75.3163       -2.9185  4386.8609     -0.9077   \n",
       "2              30    -11.9590       -3.0124   559.0582      0.9417   \n",
       "3             100     -3.3895       -2.9896    35.6139      0.7892   \n",
       "4             200     -3.0301       -2.9915     3.4799      0.8054   \n",
       "5             500     -3.0554       -3.0077     2.0244      0.8435   \n",
       "\n",
       "   median_beta1  std_beta1  test_1pct  test_5pct  \n",
       "0        0.7938    33.4404     0.1472     0.2760  \n",
       "1        0.7989    98.9208     0.2142     0.3862  \n",
       "2        0.7998    11.6853     0.6186     0.7944  \n",
       "3        0.7953     3.2351     0.9848     0.9896  \n",
       "4        0.7994     2.1781     0.9950     0.9962  \n",
       "5        0.7993     1.7780     0.9968     0.9974  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se generan 5.000 muestras para 5N = 5, 10, 30, 100, 200, 500. Se fija beta_0 = -3 y beta_1 = 0.8, y se obtienen estadísticas descriptivas. Se evalúa H0: beta_1 = 0 (poder del test). \n",
    "simulate_fgls(n_samples=5000, n_observations_list=[5, 10, 30, 100, 200, 500], beta_0_true=-3, beta_1_true=0.8, beta1_H0=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1b.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_observations</th>\n",
       "      <th>mean_beta0</th>\n",
       "      <th>median_beta0</th>\n",
       "      <th>std_beta0</th>\n",
       "      <th>mean_beta1</th>\n",
       "      <th>median_beta1</th>\n",
       "      <th>std_beta1</th>\n",
       "      <th>test_size_1pct</th>\n",
       "      <th>test_size_5pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.9583</td>\n",
       "      <td>-2.8909</td>\n",
       "      <td>4.6492</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_observations  mean_beta0  median_beta0  std_beta0  mean_beta1  \\\n",
       "0               5     -2.9583       -2.8909     4.6492      0.7981   \n",
       "\n",
       "   median_beta1  std_beta1  test_size_1pct  test_size_5pct  \n",
       "0        0.7964     0.1620          0.0068          0.0460  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_gls(n_samples=5000, n_observations=5, beta_0_true=-3, beta_1_true=0.8, beta1_H0=0.8, omega=[4, 9, 16, 25, 36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. PROPIEDADES DE MUESTRA FINITA DEL TEST DE WHITE Y DE LA CORRECIÓN POR HETEROCEDASTICIDAD.**\n",
    "\n",
    "Consideremos el siguiente modelo:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\sqrt{v_i} u_i, \\quad i = 1, \\dots, n \\tag{2}\n",
    "$$\n",
    "\n",
    "Para $n = 20$, $x_1$ se determina como una secuencia de 18 puntos espaciados uniformemente entre -1 y 1 con puntos extremos dados por -1.1 y 1.1, mientras que  $x_2$ son cuantiles de una distribución normal estándar elegidos aleatoriamente. La generación de los datos de la variable dependiente se hace con  $\\beta_0 = \\beta_1  = \\beta_2$ = 1.\n",
    "\n",
    "Existen tres diseños:\n",
    "\n",
    "1. **Diseño 0**: $u_i \\sim N(0,1)$, y $v_i = 1$ (Normalidad y homocedasticidad);\n",
    "\n",
    "2. **Diseño 1**: $u_i \\sim N(0,1)$, y $v_i = e^{0.25 x_{1i} + 0.25 x_{2i}}$ (Normalidad y heterocedasticidad);\n",
    "\n",
    "3. **Diseño 2**: $u_i \\sim t_5$, y $v_i = e^{0.25 x_{1i} + 0.25 x_{2i}}$ (No-normalidad y heterocedasticidad).\n",
    "\n",
    "Todas las simulaciones se basan en **5.000 replicaciones**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1. TEST DE HETEROCEDASTICIDAD DE WHITE.**\n",
    "\n",
    "**Ejercicios.**\n",
    "\n",
    "**a)** Para el **diseño 0**, genere 5.000 muestras de $n = 20$ observaciones a partir del modelo (2). Para cada muestra, **estime por OLS** los parámetros del modelo y realice el **test de hipótesis de White** para contrastar que $H_0$ : No hay heterocedasticidad. Reporte el **tamaño del test** al 1%, 5%, 10%.\n",
    "\n",
    "**b)** Para los **diseños 1 y 2**, genere 5.000 muestras de $n = 20$ observaciones a partir del modelo (2) y reporte el **poder del test cuando el diseño utilizado es el modelo poblacional verdadero**.\n",
    "\n",
    "**c)** Repita el punto anterior con $n = 60$.\n",
    "\n",
    "**d)** Repita el punto anterior con $n = 100$.\n",
    "\n",
    "**e)** Repita el punto anterior con $n = 200$.\n",
    "\n",
    "**f)** Repita el punto anterior con $n = 400$.\n",
    "\n",
    "**g)** Repita el punto anterior con $n = 600$.\n",
    "\n",
    "**h)** Describa detalladamente las **propiedades de muestra finita del test de White** de acuerdo a lo observado en los puntos anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2. CORRECIÓN DE LA MATRIZ DE VARIANZAS Y COVARIANZAS EN PRESENCIA DE HETEROCEDASTICIDAD.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
