{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UNIVERSIDAD TORCUATO DI TELLA**\n",
    "## **MAESTRÍA EN ECONOMETRÍA**\n",
    "\n",
    "---\n",
    "\n",
    "### **TRABAJO PRÁCTICO DE ECONOMETRÍA**\n",
    "\n",
    "- **Profesor:** González-Rozada, Martín  \n",
    "- **Ayudante:** Lening, Iara  \n",
    "- **Alumno:** Guzzi, David Alexander  (Legajo n°: 24H1970, DNI: 37.703.649)  \n",
    "\n",
    "**Ciclo Lectivo:** Tercer Trimestre, 2024  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. PROPIEDADES DE MUESTRA FINITA DE FGLS (MCGE).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "\n",
    "np.random.seed(3649)\n",
    "\n",
    "def fgls_estimation(x: np.ndarray, y: np.ndarray) -> tuple[float, float, float]:\n",
    "\n",
    "    \"\"\"\n",
    "    Realiza una estimación de Feasible Generalized Least Squares (FGLS para un modelo lineal \n",
    "    con errores heterocedásticos.\n",
    "\n",
    "    Parámetros:\n",
    "    x : array-like\n",
    "        Variable regresora.\n",
    "    y : array-like\n",
    "        Variable de respuesta.\n",
    "\n",
    "    Retorna:\n",
    "    beta0_fgls : float\n",
    "        Intercepto estimado.\n",
    "    beta1_fgls : float\n",
    "        Coeficiente estimado para el regresor.\n",
    "    se_beta1_fgls : float\n",
    "        Error estándar del coeficiente estimado para el regresor.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Estimar modelo inicial y ~ x por OLS y obtener las estimaciones de los parámetros del modelo.\n",
    "    X = np.column_stack((np.ones_like(x), x)) \n",
    "    beta_ols = np.linalg.inv(X.T @ X) @ X.T @ y \n",
    "\n",
    "    # 2. Calcular los residuos del modelo, elevarlos al cuadrado y obtener el logaritmo de los mismos.\n",
    "    u_hat = y - X @ beta_ols\n",
    "    u_hat2 = u_hat ** 2  \n",
    "    log_u_hat2 = np.log(u_hat2)\n",
    "\n",
    "    # 3. Dada la forma funcional de la heterocedasticidad de White para este modelo, sigma2 ~ x + x2, se estima por OLS usando u_hat2 como proxy de sigma2.\n",
    "    X_aux = np.column_stack((x, x**2))\n",
    "    gamma_hat = np.linalg.inv(X_aux.T @ X_aux) @ X_aux.T @ log_u_hat2\n",
    "    \n",
    "    # 4. Usar las estimaciones de la regresión auxiliar y obtener las varianzas ajustadas (no consistentes).\n",
    "    log_sigma2_hat = X_aux @ gamma_hat\n",
    "    sigma2_hat = np.exp(log_sigma2_hat)\n",
    "\n",
    "    # 5. Transformar las variables de la forma funcional de la heterocedasticidad de White dividiéndolas por sigma2_hat y estimar por OLS.\n",
    "    X_aux2 = np.column_stack((x / sigma2_hat,  x**2 / sigma2_hat))\n",
    "    u_hat2_over_sigma2_hat = u_hat2 / sigma2_hat\n",
    "    gamma_hat2 = np.linalg.inv(X_aux2.T @ X_aux2) @ X_aux2.T @ u_hat2_over_sigma2_hat\n",
    "\n",
    "    # 6. Usar las estimaciones de la segunda regresión auxiliar y obtener las varianzas ajustadas (consistentes).\n",
    "    sigma2_tilde = np.maximum(X_aux @ gamma_hat2, 1e-6) #Se asegura positividad de las varianzas. \n",
    "    omega_tilde_inv = np.linalg.inv(np.diag(sigma2_tilde)) #Se construye matriz omega inversa.  \n",
    "    \n",
    "    # 7. Aplicar GLS en la regresión de y ~ x, utilizando como ponderador la matriz omega estimada.\n",
    "    # Obs.: También se podría usar uno sobre la raíz cuadrada de sigma2 tilde como ponderador en la regresión de y ~ x.\n",
    "    \n",
    "    # Se obtienen las estimaciones de los parámetros.\n",
    "    beta_fgls = np.linalg.inv(X.T @ omega_tilde_inv @ X) @ X.T @ omega_tilde_inv @ y\n",
    "    \n",
    "    # Se obtienen las estimaciones de los errores estándar de los parámetros.\n",
    "    residuals_fgls = y - X @ beta_fgls\n",
    "    s2_fgls = (residuals_fgls.T @ omega_tilde_inv @ residuals_fgls) / ( X.shape[0] - X.shape[1])\n",
    "    var_beta_fgls = s2_fgls * np.linalg.inv(X.T @ omega_tilde_inv @ X)\n",
    "    se_beta1_fgls = np.sqrt(np.diag(var_beta_fgls))[1]   \n",
    "    \n",
    "    return beta_fgls[0], beta_fgls[1], se_beta1_fgls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_fgls(n_samples: int, n_observations_list: list[int], beta_0_true: float, beta_1_true: float, beta1_H0: float) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Simula la estimación de FGLS para distintos tamaños de muestra y evalúa la validez de un test de hipótesis.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        Número de simulaciones a realizar para cada tamaño de muestra.\n",
    "    n_observations_list : list of int\n",
    "        Lista con los distintos tamaños de muestra a evaluar.\n",
    "    beta_0_true : float\n",
    "        Valor verdadero del intercepto en la simulación.\n",
    "    beta_1_true : float\n",
    "        Valor verdadero del coeficiente del regresor en la simulación.\n",
    "    beta1_H0 : float\n",
    "        Valor hipotético de beta_1 bajo H0 para el test de hipótesis.\n",
    "\n",
    "    Returns:\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame con estadísticas de los coeficientes estimados y tasas de rechazo del test de hipótesis.\n",
    "        Columnas:\n",
    "        - 'n_observations': Tamaño de la muestra.\n",
    "        - 'mean_beta0': Media de las estimaciones de beta_0.\n",
    "        - 'median_beta0': Mediana de las estimaciones de beta_0.\n",
    "        - 'std_beta0': Desviación estándar de las estimaciones de beta_0.\n",
    "        - 'mean_beta1': Media de las estimaciones de beta_1.\n",
    "        - 'median_beta1': Mediana de las estimaciones de beta_1.\n",
    "        - 'std_beta1': Desviación estándar de las estimaciones de beta_1.\n",
    "        - 'test_size_1pct': Proporción de rechazos de H0 al 1% de significancia.\n",
    "        - 'test_size_5pct': Proporción de rechazos de H0 al 5% de significancia.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    for n_obs in n_observations_list:\n",
    "        sample_results = []\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # Generación de datos.\n",
    "            x = np.random.uniform(1, 50, n_obs) # x ~ U[1, 50]\n",
    "            u = np.random.normal(scale=x) # u ~ N(0, omega) con omega = x (errores heterocedásticos)\n",
    "            y = beta_0_true + beta_1_true * x + u\n",
    "            \n",
    "            # Estimación FGLS.\n",
    "            beta_0_hat, beta_1_hat, se_beta1_hat = fgls_estimation(x, y)\n",
    "            \n",
    "            # Test de hipótesis para beta_1 = 0.8.\n",
    "            t_stat = (beta_1_hat - beta1_H0) / se_beta1_hat\n",
    "            p_value = 2 * (1 - t.cdf(abs(t_stat), df=n_obs - 2))\n",
    "            reject_1pct = p_value < 0.01 # Rechazar H0 al 1% de significancia.\n",
    "            reject_5pct = p_value < 0.05 # Rechazar H0 al 5% de significancia.\n",
    "            \n",
    "            sample_results.append([beta_0_hat, beta_1_hat, reject_1pct, reject_5pct])\n",
    "        \n",
    "        # Convertir a DataFrame.\n",
    "        df_results = pd.DataFrame(sample_results, columns=['beta_0_hat', 'beta_1_hat', 'reject_1pct', 'reject_5pct'])\n",
    "        \n",
    "        # Calcular estadísticas.\n",
    "        mean_beta0 = df_results['beta_0_hat'].mean()\n",
    "        mean_beta1 = df_results['beta_1_hat'].mean()\n",
    "        median_beta0 = df_results['beta_0_hat'].median()\n",
    "        median_beta1 = df_results['beta_1_hat'].median()\n",
    "        std_beta0 = df_results['beta_0_hat'].std()\n",
    "        std_beta1 = df_results['beta_1_hat'].std()\n",
    "        test_size_1pct = df_results['reject_1pct'].mean() #Equivale a la proporción de rechazos de las 5000 simulaciones al 1% de significancia.\n",
    "        test_size_5pct = df_results['reject_5pct'].mean() #Equivale a la proporción de rechazos de las 5000 simulaciones al 5% de significancia.\n",
    "        \n",
    "        results.append([n_obs, mean_beta0, median_beta0, std_beta0, mean_beta1, median_beta1, std_beta1, test_size_1pct, test_size_5pct])\n",
    "    \n",
    "    results_df = pd.DataFrame(results, columns=['n_observations', 'mean_beta0', 'median_beta0', 'std_beta0', 'mean_beta1', 'median_beta1', 'std_beta1', 'test_size_1pct', 'test_size_5pct'])\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros iniciales\n",
    "test_results = simulate_fgls(n_samples=5000, n_observations_list=[5, 10, 30, 100, 200], beta_0_true=-3, beta_1_true=0.8, beta1_H0=0.8)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
