{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.845\n",
      "Model:                            OLS   Adj. R-squared:                  0.793\n",
      "Method:                 Least Squares   F-statistic:                     16.35\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):             0.0272\n",
      "Time:                        17:24:46   Log-Likelihood:                -21.674\n",
      "No. Observations:                   5   AIC:                             47.35\n",
      "Df Residuals:                       3   BIC:                             46.57\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -4.441e-15     10.661  -4.17e-16      1.000     -33.930      33.930\n",
      "x1             6.5000      1.607      4.044      0.027       1.385      11.615\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.898\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.380\n",
      "Skew:                           0.152   Prob(JB):                        0.827\n",
      "Kurtosis:                       1.684   Cond. No.                         6.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos de entrada\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "\n",
    "# Agregar constante (para incluir la ordenada al origen)\n",
    "X = sm.add_constant(x)  # Esto agrega una columna de unos para el término constante\n",
    "\n",
    "# Ajustar el modelo de regresión\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta_hat': 6.5, 'var_beta_hat': 0.45454545454545453}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "\n",
    "# Varianza del error\n",
    "sigma_squared = 100\n",
    "\n",
    "# Calcular x^T x\n",
    "xtx = np.sum(x**2)\n",
    "\n",
    "# Calcular beta sombrero\n",
    "beta_hat = np.sum(x * y) / xtx\n",
    "\n",
    "# Calcular la varianza de beta sombrero\n",
    "var_beta_hat = sigma_squared / xtx\n",
    "\n",
    "# Resultados\n",
    "{\n",
    "    \"beta_hat\": beta_hat,\n",
    "    \"var_beta_hat\": var_beta_hat\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = beta_hat * x \n",
    "e_hat = y - y_hat\n",
    "n = len(x)\n",
    "k = 1\n",
    "sigma_hat = np.sum(e_hat**2) / (n-k)\n",
    "sigma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19.5,  45.5, -26. ,  32.5, -71.5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9375"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_hat / xtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi_hat (coeficiente x sobre z)': 2.0,\n",
       " 'x_hat': array([  2.,   4.,  -4.,   8., -10.]),\n",
       " 'beta_hat_2sls': 7.2,\n",
       " 'var_beta_hat_2sls': 0.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "z = np.array([1, 2, -2, 4, -5])\n",
    "\n",
    "# Varianza del error\n",
    "sigma_squared = 100\n",
    "\n",
    "# Paso 1: Regresión de x sobre z\n",
    "ztz = np.sum(z**2)  # z^T z\n",
    "ztx = np.sum(z * x)  # z^T x\n",
    "pi_hat = ztx / ztz   # Coeficiente estimado\n",
    "\n",
    "# Calcular x sombrero\n",
    "x_hat = pi_hat * z\n",
    "\n",
    "# Paso 2: Regresión de y sobre x sombrero\n",
    "x_hat_t_x_hat = np.sum(x_hat**2)  # (x sombrero)^T x sombrero\n",
    "x_hat_t_y = np.sum(x_hat * y)     # (x sombrero)^T y\n",
    "beta_hat_2sls = x_hat_t_y / x_hat_t_x_hat\n",
    "\n",
    "# Calcular la varianza de beta sombrero\n",
    "var_beta_hat_2sls = sigma_squared / x_hat_t_x_hat\n",
    "\n",
    "# Resultados\n",
    "{\n",
    "    \"pi_hat (coeficiente x sobre z)\": pi_hat,\n",
    "    \"x_hat\": x_hat,\n",
    "    \"beta_hat_2sls\": beta_hat_2sls,\n",
    "    \"var_beta_hat_2sls\": var_beta_hat_2sls\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.283291031876401"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_beta_hat = 0.45454545454545453\n",
    "var_beta_hat_2sls = 0.5\n",
    "\n",
    "(6.5 - 7.2) / np.sqrt(var_beta_hat_2sls - var_beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta_ols': array([6.5]),\n",
       " 'beta_2sls': array([7.2]),\n",
       " 'hausman_stat': array([0.02227273]),\n",
       " 'p_value': array([0.11863614])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Datos\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "z = np.array([1, 2, -2, 4, -5])\n",
    "\n",
    "# Paso 1: Estimación por OLS sin constante\n",
    "model_ols = sm.OLS(y, x).fit()  # OLS sin constante\n",
    "beta_ols = model_ols.params\n",
    "var_beta_ols = 0.45454545\n",
    "\n",
    "# Paso 2: Estimación por 2SLS sin constante\n",
    "# Etapa 1: Regresión de x sobre z (sin constante)\n",
    "model_stage1 = sm.OLS(x, z).fit()\n",
    "x_hat = model_stage1.predict(z)\n",
    "\n",
    "# Etapa 2: Regresión de y sobre x sombrero (sin constante)\n",
    "model_2sls = sm.OLS(y, x_hat).fit()\n",
    "beta_2sls = model_2sls.params\n",
    "var_beta_2sls = 0.5\n",
    "\n",
    "# Paso 3: Estadístico de Hausman\n",
    "beta_diff = beta_ols - beta_2sls  # Diferencia entre los estimadores\n",
    "var_diff =  var_beta_2sls - var_beta_ols  # Diferencia entre varianzas\n",
    "hausman_stat = beta_diff.T * var_diff * beta_diff  # Estadístico\n",
    "\n",
    "# Usar scipy.stats.chi2.sf para calcular el p-valor\n",
    "p_value = 1 - chi2.sf(hausman_stat, df=1)  # p-valor, 1 parámetro\n",
    "\n",
    "# Resultados\n",
    "{\n",
    "    \"beta_ols\": beta_ols,\n",
    "    \"beta_2sls\": beta_2sls,\n",
    "    \"hausman_stat\": hausman_stat,\n",
    "    \"p_value\": p_value\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto crítico al 5% (chi-cuadrado, df=2): 5.991464547107979\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# Grados de libertad\n",
    "df = 2  # Cambia según el número de parámetros que estás probando\n",
    "\n",
    "# Punto crítico al 5% en la cola derecha\n",
    "chi2_critical = chi2.ppf(0.95, df)\n",
    "\n",
    "print(f\"Punto crítico al 5% (chi-cuadrado, df={df}): {chi2_critical}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto crítico al 5% (normal estándar): 1.6448536269514722\n",
      "Punto crítico al 5% (t-Student, df=1): 1.6463788172854639\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, t\n",
    "\n",
    "# Grados de libertad para t-Student\n",
    "df = 1  # Cambia según el número de grados de libertad\n",
    "\n",
    "# Punto crítico al 5% en la cola derecha para normal\n",
    "z_critical = norm.ppf(0.95)  # Normal estándar (media=0, desviación estándar=1)\n",
    "\n",
    "# Punto crítico al 5% en la cola derecha para t-Student\n",
    "t_critical = t.ppf(0.95, 1000)\n",
    "\n",
    "print(f\"Punto crítico al 5% (normal estándar): {z_critical}\")\n",
    "print(f\"Punto crítico al 5% (t-Student, df={df}): {t_critical}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13664\\2666195302.py:35: RuntimeWarning: invalid value encountered in sqrt\n",
      "  hausman_stat = beta_diff / np.sqrt(var_diff)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beta_ols': 6.5, 'beta_2sls': 7.2, 'hausman_stat': nan, 'p_value': nan}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Datos\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "z = np.array([1, 2, -2, 4, -5])\n",
    "\n",
    "# Estimación por OLS sin constante (sin agregar constante)\n",
    "model_ols = sm.OLS(y, x).fit()  # OLS sin constante\n",
    "beta_ols = model_ols.params[0]  # Coeficiente estimado por OLS\n",
    "var_beta_ols = model_ols.cov_params()[0, 0]  # Varianza del estimador OLS\n",
    "\n",
    "# Estimación por 2SLS sin constante\n",
    "# Etapa 1: Regresión de x sobre z (sin constante)\n",
    "model_stage1 = sm.OLS(x, z).fit()\n",
    "x_hat = model_stage1.predict(z)\n",
    "\n",
    "# Etapa 2: Regresión de y sobre x sombrero (sin constante)\n",
    "model_2sls = sm.OLS(y, x_hat).fit()\n",
    "beta_2sls = model_2sls.params[0]  # Coeficiente estimado por 2SLS\n",
    "var_beta_2sls = model_2sls.cov_params()[0, 0]  # Varianza del estimador 2SLS\n",
    "\n",
    "# Estimación por MCC\n",
    "# Para ilustrar, tomamos los mismos resultados de OLS como MCC (esto es solo un ejemplo)\n",
    "beta_mcc = beta_ols\n",
    "var_beta_mcc = var_beta_ols\n",
    "\n",
    "# Calcular el estadístico de Hausman\n",
    "beta_diff = beta_ols - beta_2sls  # Diferencia entre los estimadores\n",
    "var_diff = var_beta_2sls - var_beta_mcc  # Diferencia entre las varianzas (2SLS - MCC)\n",
    "\n",
    "# Estadístico de Hausman\n",
    "hausman_stat = beta_diff / np.sqrt(var_diff)\n",
    "\n",
    "# Calcular el p-valor usando la distribución normal estándar (asumiendo que sigue N(0,1))\n",
    "p_value = 1 - norm.cdf(hausman_stat)  # p-valor\n",
    "\n",
    "# Resultados\n",
    "{\n",
    "    \"beta_ols\": beta_ols,\n",
    "    \"beta_2sls\": beta_2sls,\n",
    "    \"hausman_stat\": hausman_stat,\n",
    "    \"p_value\": p_value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.943\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.905\n",
      "Method:                 Least Squares   F-statistic:                              24.82\n",
      "Date:                Mon, 09 Dec 2024   Prob (F-statistic):                      0.0136\n",
      "Time:                        10:16:46   Log-Likelihood:                         -19.173\n",
      "No. Observations:                   5   AIC:                                      42.35\n",
      "Df Residuals:                       3   BIC:                                      41.57\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.5000      3.233     -0.155      0.887     -10.788       9.788\n",
      "x2             7.7000      3.390      2.271      0.108      -3.090      18.490\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.888\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.025\n",
      "Skew:                          -1.105   Prob(JB):                        0.599\n",
      "Kurtosis:                       2.810   Cond. No.                         6.49\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos de entrada\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "z = np.array([2, 4, -4, 8, -10])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "\n",
    "# Crear matriz de diseño con x y z como variables explicativas\n",
    "X = np.column_stack((x, z))  # Combina x y z en una matriz\n",
    "# X = sm.add_constant(X)  # Agregar constante al modelo\n",
    "\n",
    "# Ajustar el modelo de regresión\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import linearmodels.iv.model as lm\n",
    "\n",
    "houseprices = sm.datasets.get_rdataset(dataname=\"HousePrices\", package=\"AER\", cache=True).data\n",
    "print(houseprices.iloc[:, list(range(3)) + [5] + [10]].head())\n",
    "\n",
    "mlr1 = smf.ols(formula=\"price ~ lotsize + bedrooms\", data=houseprices).fit()\n",
    "\n",
    "mdatac = sm.add_constant(data=houseprices, prepend=False)\n",
    "mlr2 = lm.IV2SLS(dependent=mdatac[\"price\"], exog=mdatac[[\"const\", \"bedrooms\"]], endog=mdatac[\"lotsize\"], instruments=mdatac[[\"driveway\", \"garage\"]]).fit(cov_type=\"homoskedastic\", debiased=True)\n",
    "\n",
    "print(mlr2.wu_hausman())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "instruments [exog instruments]  do not have full column rank",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m60\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m mlr2 \u001b[38;5;241m=\u001b[39m \u001b[43mlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIV2SLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdependent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(cov_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhomoskedastic\u001b[39m\u001b[38;5;124m\"\u001b[39m, debiased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(mlr2\u001b[38;5;241m.\u001b[39mwu_hausman())\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\linearmodels\\iv\\model.py:896\u001b[0m, in \u001b[0;36mIV2SLS.__init__\u001b[1;34m(self, dependent, exog, endog, instruments, weights)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    888\u001b[0m     dependent: IVDataLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    893\u001b[0m     weights: IVDataLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    894\u001b[0m ):\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIV-2SLS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 896\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdependent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\linearmodels\\iv\\model.py:557\u001b[0m, in \u001b[0;36m_IVLSModelBase.__init__\u001b[1;34m(self, dependent, exog, endog, instruments, weights, fuller, kappa)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    548\u001b[0m     dependent: IVDataLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    555\u001b[0m     kappa: linearmodels\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mOptionalNumeric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    556\u001b[0m ):\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdependent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstruments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuller\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\linearmodels\\iv\\model.py:207\u001b[0m, in \u001b[0;36m_IVModelBase.__init__\u001b[1;34m(self, dependent, exog, endog, instruments, weights, fuller, kappa)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instr_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mcols \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruments\u001b[38;5;241m.\u001b[39mcols\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependent\u001b[38;5;241m.\u001b[39mrows\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_method\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIV-LIML\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\linearmodels\\iv\\model.py:343\u001b[0m, in \u001b[0;36m_IVModelBase._validate_inputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressors [exog endog] do not have full \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn rank\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matrix_rank(z) \u001b[38;5;241m<\u001b[39m z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruments [exog instruments]  do not have \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull column rank\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_constant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_const_loc \u001b[38;5;241m=\u001b[39m has_constant(x)\n",
      "\u001b[1;31mValueError\u001b[0m: instruments [exog instruments]  do not have full column rank"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import linearmodels.iv.model as lm\n",
    "\n",
    "\n",
    "# Datos de entrada\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "z = np.array([2, 4, -4, 8, -10])\n",
    "y = np.array([20, 30, -50, 60, -60])\n",
    "\n",
    "mlr2 = lm.IV2SLS(dependent=y, exog=z, endog=x, instruments=z).fit(cov_type=\"homoskedastic\", debiased=True)\n",
    "\n",
    "print(mlr2.wu_hausman())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Hausman test of exogeneity\n",
      "H0: All endogenous variables are exogenous\n",
      "Statistic: 5.1579\n",
      "P-value: 0.1078\n",
      "Distributed: F(1,3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "# Datos de entrada\n",
    "x = np.array([3, 7, -4, 5, -11])      # Variable endógena\n",
    "z = np.array([2, 4, -4, 8, -10])      # Instrumento\n",
    "y = np.array([20, 30, -50, 60, -60])  # Variable dependiente\n",
    "\n",
    "# Ajuste del modelo IV con 2SLS\n",
    "mlr2 = IV2SLS(\n",
    "    dependent=y,      # Variable dependiente\n",
    "    exog=None,        # Sin variables exógenas\n",
    "    endog=x,          # Variable endógena\n",
    "    instruments=z     # Instrumento para la variable endógena\n",
    ").fit(cov_type=\"unadjusted\", debiased=True)\n",
    "\n",
    "print(mlr2.wu_hausman())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes estimados (beta_hat): [1. 2.]\n",
      "Estimador insesgado de sigma^2: 0.6666666666666666\n",
      "Varianza insesgada de beta_2: 0.009009009009009009\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [1, 2],\n",
    "    [1, -5],\n",
    "    [1, 5],\n",
    "    [1, -4]\n",
    "])  # Matriz X\n",
    "y = np.array([4, 6, -9, 11, -7])  # Vector y\n",
    "\n",
    "# Paso 1: Calcular (X'X)^(-1)\n",
    "XtX_inv = np.linalg.inv(X.T @ X)\n",
    "\n",
    "# Paso 2: Calcular estimadores OLS: β̂ = (X'X)^(-1) X'y\n",
    "beta_hat = XtX_inv @ (X.T @ y)\n",
    "\n",
    "# Paso 3: Calcular residuos: ê = y - Xβ̂\n",
    "residuals = y - X @ beta_hat\n",
    "\n",
    "# Paso 4: Estimar sigma^2 insesgado: σ̂^2 = (ê'ê) / (n - k)\n",
    "n, k = X.shape  # Número de observaciones y parámetros\n",
    "sigma2_hat = (residuals.T @ residuals) / (n - k)\n",
    "\n",
    "# Paso 5: Estimar Var(β̂2): σ̂^2 * [(X'X)^(-1)](2,2)\n",
    "var_beta2_hat = sigma2_hat * XtX_inv[1, 1]\n",
    "\n",
    "# Resultados\n",
    "print(\"Coeficientes estimados (beta_hat):\", beta_hat)\n",
    "print(\"Estimador insesgado de sigma^2:\", sigma2_hat)\n",
    "print(\"Varianza insesgada de beta_2:\", var_beta2_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes estimados (beta_hat): [1. 2.]\n",
      "Estimador insesgado de sigma^2: 0.6666666666666666\n",
      "Varianza insesgada de beta_2: 0.00900900900900901\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [1, 2],\n",
    "    [1, -5],\n",
    "    [1, 5],\n",
    "    [1, -4]\n",
    "])  # Matriz X\n",
    "y = np.array([4, 6, -9, 11, -7])  # Vector y\n",
    "\n",
    "# Ajuste del modelo OLS con statsmodels\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtener estimador insesgado de sigma^2\n",
    "sigma2_hat = model.mse_resid\n",
    "\n",
    "# Extraer la matriz (X'X)^(-1) del modelo\n",
    "XtX_inv = model.normalized_cov_params\n",
    "\n",
    "# Varianza de beta_2 (segundo coeficiente)\n",
    "var_beta2_hat = sigma2_hat * XtX_inv[1, 1]\n",
    "\n",
    "# Resultados\n",
    "print(\"Coeficientes estimados (beta_hat):\", model.params)\n",
    "print(\"Estimador insesgado de sigma^2:\", sigma2_hat)\n",
    "print(\"Varianza insesgada de beta_2:\", var_beta2_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes estimados (beta_hat): [1.37681159 1.88405797]\n",
      "Estimador insesgado de sigma^2: 1.3623188405797102\n",
      "Varianza insesgada de beta_2: 0.01645312609395786\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [1, 2],\n",
    "    [1, -5],\n",
    "    [1, 5],\n",
    "    [1, -5]\n",
    "])  # Matriz X\n",
    "y = np.array([4, 6, -9, 11, -7])  # Vector y\n",
    "\n",
    "# Ajuste del modelo OLS con statsmodels\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtener estimador insesgado de sigma^2\n",
    "sigma2_hat = model.mse_resid\n",
    "\n",
    "# Extraer la matriz (X'X)^(-1) del modelo\n",
    "XtX_inv = model.normalized_cov_params\n",
    "\n",
    "# Varianza de beta_2 (segundo coeficiente)\n",
    "var_beta2_hat = sigma2_hat * XtX_inv[1, 1]\n",
    "\n",
    "# Resultados\n",
    "print(\"Coeficientes estimados (beta_hat):\", model.params)\n",
    "print(\"Estimador insesgado de sigma^2:\", sigma2_hat)\n",
    "print(\"Varianza insesgada de beta_2:\", var_beta2_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366600265340756"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de los residuos (con intercepto): 1.3877787807814457e-14\n",
      "Suma de los residuos (sin intercepto): 1.2210276724038787\n",
      "Diferencia en la suma de residuos: -1.221027672403865\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Crear datos simulados\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.rand(n, 1)  # Variable independiente\n",
    "Y = 3 * X.squeeze() + np.random.normal(0, 0.2, n)  # Variable dependiente con algo de ruido\n",
    "\n",
    "# Convertir X a un DataFrame para evitar advertencias\n",
    "X_df = pd.DataFrame(X, columns=[\"X\"])\n",
    "\n",
    "# Modelo con intercepto\n",
    "model_with_intercept = LinearRegression()\n",
    "model_with_intercept.fit(X, Y)\n",
    "y_pred_with_intercept = model_with_intercept.predict(X)\n",
    "residuals_with_intercept = Y - y_pred_with_intercept\n",
    "\n",
    "# Modelo sin intercepto\n",
    "model_without_intercept = LinearRegression(fit_intercept=False)\n",
    "model_without_intercept.fit(X, Y)\n",
    "y_pred_without_intercept = model_without_intercept.predict(X)\n",
    "residuals_without_intercept = Y - y_pred_without_intercept\n",
    "\n",
    "# Sumar residuos\n",
    "sum_residuals_with_intercept = np.sum(residuals_with_intercept)\n",
    "sum_residuals_without_intercept = np.sum(residuals_without_intercept)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Suma de los residuos (con intercepto):\", sum_residuals_with_intercept)\n",
    "print(\"Suma de los residuos (sin intercepto):\", sum_residuals_without_intercept)\n",
    "\n",
    "# Analizar diferencias\n",
    "print(\"Diferencia en la suma de residuos:\", sum_residuals_with_intercept - sum_residuals_without_intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes del modelo completo: [ 1.93165494 -2.85613772]\n",
      "Coeficiente de la regresión parcial (residuos): -23499388839769.58\n",
      "Correlación parcial entre Y y X1: 0.9461216502399327\n",
      "Signos coinciden: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Crear datos simulados\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X1 = np.random.rand(n, 1)  # Primer regresor\n",
    "X2 = np.random.rand(n, 1)  # Segundo regresor\n",
    "Y = 2 * X1.squeeze() - 3 * X2.squeeze() + np.random.normal(0, 0.2, n)  # Variable dependiente con ruido\n",
    "\n",
    "# Combinar regresores\n",
    "X = np.hstack([X1, X2])\n",
    "\n",
    "# Modelo completo con todos los regresores\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(X, Y)\n",
    "coefficients_full = model_full.coef_\n",
    "print(\"Coeficientes del modelo completo:\", coefficients_full)\n",
    "\n",
    "# Regresión de Y contra X2 para obtener residuos (parcialización del regresando)\n",
    "model_Y_X2 = LinearRegression()\n",
    "model_Y_X2.fit(X2, Y)\n",
    "residuals_Y = Y - model_Y_X2.predict(X2)\n",
    "\n",
    "# Regresión de X1 contra X2 para obtener residuos (parcialización del regresor)\n",
    "model_X1_X2 = LinearRegression()\n",
    "model_X1_X2.fit(X2, X1)\n",
    "residuals_X1 = X1.squeeze() - model_X1_X2.predict(X2)\n",
    "\n",
    "# Regresión de los residuos de Y contra los residuos de X1\n",
    "model_residuals = LinearRegression()\n",
    "model_residuals.fit(residuals_X1, residuals_Y)\n",
    "coef_residuals = model_residuals.coef_[0]\n",
    "\n",
    "print(\"Coeficiente de la regresión parcial (residuos):\", coef_residuals)\n",
    "\n",
    "# Comparar signo con la correlación parcial\n",
    "correlation_partial = np.corrcoef(residuals_Y, residuals_X1)[0, 1]\n",
    "print(\"Correlación parcial entre Y y X1:\", correlation_partial)\n",
    "print(\"Signos coinciden:\", np.sign(coef_residuals) == np.sign(correlation_partial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.300\n",
      "Model:                            OLS   Adj. R-squared (uncentered):             -0.050\n",
      "Method:                 Least Squares   F-statistic:                              1.385\n",
      "Date:                Sun, 15 Dec 2024   Prob (F-statistic):                       0.360\n",
      "Time:                        21:40:33   Log-Likelihood:                         -4.4880\n",
      "No. Observations:                   3   AIC:                                      10.98\n",
      "Df Residuals:                       2   BIC:                                      10.07\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:                  HC0                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.5000      0.425      1.177      0.360      -1.328       2.328\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   0.714\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.421\n",
      "Skew:                          -0.528   Prob(JB):                        0.810\n",
      "Kurtosis:                       1.500   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors are heteroscedasticity robust (HC0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos\n",
    "x = np.array([1, 2, -1])\n",
    "y = np.array([0, 2, 1])\n",
    "\n",
    "# Modelo de regresión\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# Resultados con errores estándar robustos de White\n",
    "robust_cov = model.get_robustcov_results(cov_type='HC0')\n",
    "\n",
    "# Imprimir resumen del modelo con errores estándar robustos\n",
    "print(robust_cov.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la primera regresión (x ~ z):\n",
      "Coeficiente: 2.0\n",
      "\n",
      "Resultados de la segunda regresión (y ~ x + xsombrero):\n",
      "Coeficientes: [-0.5  7.7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir los datos\n",
    "Y = np.array([20, 30, -50, 60, -60])\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "z = np.array([1, 2, -2, 4, -5])\n",
    "\n",
    "# Primera regresión: x en función de z\n",
    "beta_x_z = np.sum(z * x) / np.sum(z * z)  # Coeficiente\n",
    "xsombrero = z * beta_x_z  # Valores ajustados (xsombrero)\n",
    "\n",
    "# Segunda regresión: y en función de x y xsombrero\n",
    "X_combined = np.column_stack((x, xsombrero))  # Combinar x y xsombrero\n",
    "beta_y_x_xsombrero = np.linalg.inv(X_combined.T @ X_combined) @ X_combined.T @ Y  # Coeficientes\n",
    "\n",
    "# Resultados\n",
    "print(\"Resultados de la primera regresión (x ~ z):\")\n",
    "print(f\"Coeficiente: {beta_x_z}\")\n",
    "\n",
    "print(\"\\nResultados de la segunda regresión (y ~ x + xsombrero):\")\n",
    "print(f\"Coeficientes: {beta_y_x_xsombrero}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5. , -5. ],\n",
       "       [-5. ,  5.5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * np.linalg.inv(X_combined.T @ X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.283291031876401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.7 / np.sqrt(5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la primera regresión (x ~ z):\n",
      "Coeficiente: 2.0\n",
      "\n",
      "Resultados de la segunda regresión (y ~ x + xsombrero):\n",
      "Coeficientes: [-0.5  7.7]\n",
      "\n",
      "Promedio de Y:\n",
      "Promedio: 0.0\n",
      "\n",
      "Regresión con término de ordenada (y ~ 1 + x):\n",
      "Coeficientes: [-6.66133815e-16  6.50000000e+00]\n",
      "\n",
      "Regresión sin término de ordenada (y ~ x):\n",
      "Coeficiente: 6.5\n",
      "\n",
      "El promedio de Y es cero. Esto ocurre cuando los valores de Y están simétricamente distribuidos alrededor del origen.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir los datos\n",
    "Y = np.array([20, 30, -50, 60, -60])\n",
    "x = np.array([3, 7, -4, 5, -11])\n",
    "z = np.array([1, 2, -2, 4, -5])\n",
    "\n",
    "# Primera regresión: x en función de z\n",
    "beta_x_z = np.sum(z * x) / np.sum(z * z)  # Coeficiente\n",
    "xsombrero = z * beta_x_z  # Valores ajustados (xsombrero)\n",
    "\n",
    "# Segunda regresión: y en función de x y xsombrero\n",
    "X_combined = np.column_stack((x, xsombrero))  # Combinar x y xsombrero\n",
    "beta_y_x_xsombrero = np.linalg.inv(X_combined.T @ X_combined) @ X_combined.T @ Y  # Coeficientes\n",
    "\n",
    "# Promedio de Y\n",
    "promedio_Y = np.mean(Y)\n",
    "\n",
    "# Regresión con término de ordenada (intercepto)\n",
    "X_with_intercept = np.column_stack((np.ones(len(x)), x))  # Agregar constante\n",
    "beta_with_intercept = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ Y\n",
    "\n",
    "# Regresión sin término de ordenada\n",
    "beta_no_intercept = np.sum(x * Y) / np.sum(x * x)\n",
    "\n",
    "# Resultados\n",
    "print(\"Resultados de la primera regresión (x ~ z):\")\n",
    "print(f\"Coeficiente: {beta_x_z}\")\n",
    "\n",
    "print(\"\\nResultados de la segunda regresión (y ~ x + xsombrero):\")\n",
    "print(f\"Coeficientes: {beta_y_x_xsombrero}\")\n",
    "\n",
    "print(\"\\nPromedio de Y:\")\n",
    "print(f\"Promedio: {promedio_Y}\")\n",
    "\n",
    "print(\"\\nRegresión con término de ordenada (y ~ 1 + x):\")\n",
    "print(f\"Coeficientes: {beta_with_intercept}\")\n",
    "\n",
    "print(\"\\nRegresión sin término de ordenada (y ~ x):\")\n",
    "print(f\"Coeficiente: {beta_no_intercept}\")\n",
    "\n",
    "# Discusión\n",
    "if promedio_Y == 0:\n",
    "    print(\"\\nEl promedio de Y es cero. Esto ocurre cuando los valores de Y están simétricamente distribuidos alrededor del origen.\")\n",
    "else:\n",
    "    print(\"\\nEl promedio de Y no es cero. Esto indica que hay un sesgo en los valores de Y respecto al origen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
